name: Run accessibility tests on JupyterLab
description: |
  Builds JupyterLab from source, then runs accessibility tests against it using
  Playwright. Outputs the results to a markdown file which is then copied to the
  GitHub workflow run summary.
# see https://github.com/actions/checkout more details on the inputs accepted
inputs:
  repository:
    description: JupyterLab repository, for example gabalafou/jupyterlab
  ref:
    description: ref, branch, or SHA
  test_project:
    # https://playwright.dev/docs/test-advanced#projects
    description: |
      The Playwright test project to run (for example, "regression" to run only
      the accessibility regression tests)
runs:
  using: composite
  steps:
    - name: List environment variables
      run: env
      shell: bash

    - name: Checkout testing repo 🛎
      uses: actions/checkout@v3
      with:
        # Would be nice if ${{ github.action_repository }} worked, because then
        # this repo could be forked without needing to change this line. See:
        # https://github.com/Quansight-Labs/jupyter-a11y-testing/issues/28
        repository: Quansight-Labs/jupyter-a11y-testing

    - name: Setup node 🔺
      uses: actions/setup-node@v3
      with:
        node-version: 16

    - name: Install node dependencies 🧶
      run: |
        echo "::group::Installing node dependencies 🧶"
        npm install
        npx playwright install --with-deps chromium
        echo "::endgroup::"
        echo "npm_path=$(which npm)" >> $GITHUB_ENV
      shell: bash -l {0}
      working-directory: testing/jupyterlab

    - name: Cache conda 🧠
      uses: actions/cache@v3
      env:
        # Increase this value to reset cache if environment.yml has not changed
        CACHE_NUMBER: 0
      with:
        path: ~/conda_pkgs_dir
        key: ${{ runner.os }}-conda-${{ env.CACHE_NUMBER }}-${{
          hashFiles('./testing/jupyterlab/environment.yml') }}

    - name: Install miniconda 🐍
      uses: conda-incubator/setup-miniconda@v2
      with:
        miniforge-variant: Mambaforge
        miniforge-version: latest
        use-mamba: true
        environment-file: ./testing/jupyterlab/environment.yml
        activate-environment: a11y-tests
        auto-activate-base: false
        use-only-tar-bz2: true

    - name: Checks on environment 🔍
      run: |
        echo "::group::Check conda info 🔍"
        conda info
        conda env list
        echo $CONDA_PREFIX
        echo "::endgroup::"
      shell: bash -l {0}

    - name: Checkout JupyterLab
      uses: actions/checkout@v3
      with:
        repository: ${{ inputs.repository || 'jupyterlab/jupyterlab' }}
        ref: ${{ inputs.ref || 'master' }}
        path: jupyterlab

    - name: Build JupyterLab 🏗
      run: |
        echo "::group::Install and build JupyterLab 🏗"
        conda run --prefix $CONDA_PREFIX ./scripts/ci_install.sh
        conda run --prefix $CONDA_PREFIX jlpm run build
        echo "::endgroup::"
      shell: bash -l {0}
      working-directory: jupyterlab

    - name: Check JupyterLab installation
      run: |
        which jupyter
        jupyter lab --version
      shell: bash -l {0}

    - name: Run tests  ✅
      # we want the workflow to continue - i.e. we expect a11y errors so we want to diagnose and
      # get the output summary
      continue-on-error: true
      run: |
        if [[ "${{ inputs.test_project }}" ]]
        then
          ${{ env.npm_path }} test -- --project="${{ inputs.test_project }}"
        else
          ${{ env.npm_path }} test
        fi
      shell: bash -l {0}
      working-directory: testing/jupyterlab

    - name: Write GitHub Summary 📝
      run: cat test-results/jupyterlab-a11y-regression-test-results.md >> $GITHUB_STEP_SUMMARY
      shell: bash -l {0}
      working-directory: testing/jupyterlab

    - name: Get run refs 🏷
      id: getrefs
      run: |
        export raw_branch=${GITHUB_REF#refs/heads/}
        echo "branch=${raw_branch//\//-}" >> $GITHUB_OUTPUT
        echo "sha8=$(echo ${GITHUB_SHA} | cut -c1-8)" >> $GITHUB_OUTPUT
      shell: bash -l {0}

    - name: Upload Playwright report and test results 📤
      uses: actions/upload-artifact@v3
      # using default retention policy = 90 days
      with:
        name: jupyterlab-a11y-tests-${{ steps.getrefs.outputs.branch }}-${{ steps.getrefs.outputs.sha8 }}
        path: |
          ./testing/jupyterlab/playwright-report/
          ./testing/jupyterlab/test-results/jupyterlab-a11y-regression-test-results.json
          ./testing/jupyterlab/README.md
